{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T22:39:06.324164Z",
     "start_time": "2021-10-26T22:39:05.727231Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-29T21:04:48.005097Z",
     "iopub.status.busy": "2021-10-29T21:04:48.004897Z",
     "iopub.status.idle": "2021-10-29T21:04:55.365064Z",
     "shell.execute_reply": "2021-10-29T21:04:55.364145Z",
     "shell.execute_reply.started": "2021-10-29T21:04:48.005038Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import requests\n",
    "import inflection\n",
    "\n",
    "import seaborn    as sns\n",
    "import xgboost    as xgb\n",
    "import statistics as st\n",
    "import numpy      as np\n",
    "import pandas     as pd\n",
    "\n",
    "\n",
    "from scipy                 import stats  as ss\n",
    "from matplotlib            import pyplot as plt\n",
    "from tabulate              import tabulate\n",
    "from boruta                import BorutaPy\n",
    "\n",
    "from IPython.display       import Image\n",
    "from IPython.core.display  import HTML\n",
    "\n",
    "from sklearn.metrics       import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble      import RandomForestRegressor\n",
    "from sklearn.linear_model  import LinearRegression, Lasso\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T23:53:17.355991Z",
     "start_time": "2021-03-26T23:53:17.283538Z"
    },
    "code_folding": [
     0,
     7
    ],
    "execution": {
     "iopub.execute_input": "2021-10-29T21:04:55.366503Z",
     "iopub.status.busy": "2021-10-29T21:04:55.366260Z",
     "iopub.status.idle": "2021-10-29T21:04:55.456319Z",
     "shell.execute_reply": "2021-10-29T21:04:55.454497Z",
     "shell.execute_reply.started": "2021-10-29T21:04:55.366471Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def jupyter_settings():\n",
    "    %matplotlib inline\n",
    "    %pylab inline\n",
    "    %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "    plt.style.use('ggplot')\n",
    "    plt.rcParams['figure.figsize'] = [16, 12]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "\n",
    "    display(HTML('<style>.container { width:100% !important; }</style>'))\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.options.display.float_format = '{:,.4f}'.format\n",
    "    pd.set_option('display.expand_frame_repr', False)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "\n",
    "    sns.set()\n",
    "    \n",
    "jupyter_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st Order Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T23:53:17.600434Z",
     "start_time": "2021-03-26T23:53:17.358014Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2021-10-29T21:04:55.459386Z",
     "iopub.status.busy": "2021-10-29T21:04:55.458886Z",
     "iopub.status.idle": "2021-10-29T21:04:55.599615Z",
     "shell.execute_reply": "2021-10-29T21:04:55.598977Z",
     "shell.execute_reply.started": "2021-10-29T21:04:55.459322Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# First Order Stats - Applied on Numerical Attributes\n",
    "def descriptive_stats_1st_order(df):\n",
    "    # Central Tendency - mean, median, mode\n",
    "    ct1 = pd.DataFrame(df.apply(np.mean)).T\n",
    "    ct2 = pd.DataFrame(df.apply(np.median)).T\n",
    "    ct3 = pd.DataFrame(df.apply(st.mode)).T\n",
    "\n",
    "    # Dispersion\n",
    "    d1 = pd.DataFrame(df.apply(np.std)).T\n",
    "    d2 = pd.DataFrame(df.apply(min)).T\n",
    "    d3 = pd.DataFrame(df.apply(max)).T\n",
    "    d4 = pd.DataFrame(df.apply(lambda x: x.max() - x.min())).T\n",
    "    d5 = pd.DataFrame(df.apply(lambda x: np.quantile(x, .25))).T\n",
    "    d6 = pd.DataFrame(df.apply(lambda x: np.quantile(x, .75))).T\n",
    "    d7 = pd.DataFrame(df.apply(lambda x: x.skew())).T\n",
    "    d8 = pd.DataFrame(df.apply(lambda x: x.kurtosis())).T\n",
    "\n",
    "    # Concatenate\n",
    "    ds = pd.concat([ct1, ct2, ct3, d1, d2, d3, d4,\n",
    "                    d5, d6, d7, d8]).T.reset_index()\n",
    "    ds.columns = ['attributes', 'mean', 'median', 'mode', 'std',\n",
    "                  'min', 'max', 'range', 'Q1', 'Q3', 'skewness', 'kurtosis']\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cramer V - chi²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T00:57:45.528321Z",
     "start_time": "2020-07-14T00:57:45.519349Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-29T21:04:55.601336Z",
     "iopub.status.busy": "2021-10-29T21:04:55.600969Z",
     "iopub.status.idle": "2021-10-29T21:04:55.708832Z",
     "shell.execute_reply": "2021-10-29T21:04:55.707928Z",
     "shell.execute_reply.started": "2021-10-29T21:04:55.601311Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# chi2 formula - Applied on Categorical Attributes\n",
    "def cramer_v( x, y ):\n",
    "    # calculate confusion matrix (cm), contingency table\n",
    "    cm = pd.crosstab( x, y ).to_numpy()\n",
    "    n = cm.sum()\n",
    "    r, k = cm.shape\n",
    "    \n",
    "    # calculate chi2\n",
    "    chi2 = ss.chi2_contingency( cm )[0]\n",
    "    # chi2 correction\n",
    "    chi2corr = max( 0, chi2 - (k-1)*(r-1)/(n-1) )\n",
    "    \n",
    "    # k correction\n",
    "    kcorr = k - (k-1)**2/(n-1)\n",
    "    # r correction\n",
    "    rcorr = r - (r-1)**2/(n-1)\n",
    "    \n",
    "    # return Cramer V\n",
    "    return np.sqrt( (chi2corr/n) / ( min( kcorr-1, rcorr-1 ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE Metric - Mean Absolute Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE metric was defined in sklean.metrics module (see _imports_ section),\n",
    "Your result it's in same numeric base of response variable. However, it is good practice to compare with the response variable's range of values to understand your real impact.\n",
    "\n",
    "Your sumary is the \"mean of all individual errors of prediction\".\n",
    "\n",
    "It's calculated with bellow formula where ${n}$ is the total length of amostrage, ${i}$ is the index of focused occur, ${y}$ is the real value and $\\hat{y}$ is predicted value. \n",
    "\n",
    "We use module operation  for compensate negative values when model is overestimating prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T14:46:23.801320Z",
     "iopub.status.busy": "2021-10-19T14:46:23.800968Z",
     "iopub.status.idle": "2021-10-19T14:46:23.806964Z",
     "shell.execute_reply": "2021-10-19T14:46:23.806063Z",
     "shell.execute_reply.started": "2021-10-19T14:46:23.801279Z"
    }
   },
   "source": [
    "MAE = $ \\frac{ \\sum_{i=1}^n | y_{i} - \\hat{y}_{i}| }{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It assigns the same weight to all errors.\n",
    "- It's robust against outliers.\n",
    "- It's easy to understand for business team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:04:55.710601Z",
     "iopub.status.busy": "2021-10-29T21:04:55.710291Z",
     "iopub.status.idle": "2021-10-29T21:04:55.885101Z",
     "shell.execute_reply": "2021-10-29T21:04:55.882567Z",
     "shell.execute_reply.started": "2021-10-29T21:04:55.710563Z"
    }
   },
   "outputs": [],
   "source": [
    "pass # MAE - only for code understand - Defined in SciKit Learn Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE Metric - Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE metric was defined in sklean.metrics module (see _imports_ section). Your result it's in same numeric base of response variable, is squared !\n",
    "\n",
    "It's calculated with bellow formula where ${n}$ is the total length of amostrage, ${i}$ is the index of focused occur, ${y}$ is the real value and $\\hat{y}$ is predicted value. \n",
    "\n",
    "We use the square operation to compensate for negative values when the model is overestimating the prediction and the square root to get the real numbers again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE = $  \\sqrt {\\frac{\\sum_{i=1}^n     \\left( y_{i} - \\hat{y}_{i}\\right) ^2}{n}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It assigns more weight to outliers.\n",
    "- Goot to calculate the impact of outliers on predictions. \n",
    "- Isn't easy to understand for business team, most used to calculate the ML models performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:04:55.888405Z",
     "iopub.status.busy": "2021-10-29T21:04:55.887780Z",
     "iopub.status.idle": "2021-10-29T21:04:56.044810Z",
     "shell.execute_reply": "2021-10-29T21:04:56.041977Z",
     "shell.execute_reply.started": "2021-10-29T21:04:55.888321Z"
    }
   },
   "outputs": [],
   "source": [
    "pass # RMSE - only for code understand - Defined in SciKit Learn Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPE Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAPE Metric is defined in the function bellow. Your result is a percentage representation of MAE Metric (above). It's good practice to compare with the response variable's range of values to understand your real impact.\n",
    "\n",
    "It's calculated with bellow formula where ${n}$ is the total length of amostrage, ${i}$ is the index of focused occur, ${y}$ is the real value and $\\hat{y}$ is predicted value. \n",
    "\n",
    "We use module operation  for compensate negative values when model is overestimating prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAPE% = $\n",
    "\\frac{100 \\sum_{i=1}^n | \\frac{y_{i} - \\hat{y}_{i}}{y_{i}} |}{n}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Shows how far a prediction is from the actual value, on average.\n",
    "- It's good to easy understand for business team.\n",
    "\n",
    "- Can not be used if the response variable can be ZERO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T00:57:46.388253Z",
     "start_time": "2020-07-14T00:57:46.362323Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-29T21:04:56.050027Z",
     "iopub.status.busy": "2021-10-29T21:04:56.049031Z",
     "iopub.status.idle": "2021-10-29T21:04:56.203721Z",
     "shell.execute_reply": "2021-10-29T21:04:56.200987Z",
     "shell.execute_reply.started": "2021-10-29T21:04:56.049900Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# mean absolute percentage error formula - applied on ml_error function below\n",
    "def mean_absolute_percentage_error(y, yhat):\n",
    "    return np.mean( np.abs( ( y - yhat ) / y) * 100 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPE Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPE Metric is defined in the function below. Your result is a percentage representation. It is good to calculate if the model is Overfitting or Underfitting (and how much).\n",
    "\n",
    "It's calculated with bellow formula where ${n}$ is the total length of amostrage, ${i}$ is the index of focused occur, ${y}$ is the real value and $\\hat{y}$ is predicted value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPE% = $\n",
    "\\frac{100 \\sum_{i=1}^n \\frac{y_{i} - \\hat{y}_{i}}{y_{i}} }{n}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can not be used if the response variable can be ZERO.\n",
    "- Negative values mean that the model is Overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T00:57:46.388253Z",
     "start_time": "2020-07-14T00:57:46.362323Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-29T21:04:56.207364Z",
     "iopub.status.busy": "2021-10-29T21:04:56.206711Z",
     "iopub.status.idle": "2021-10-29T21:04:56.361812Z",
     "shell.execute_reply": "2021-10-29T21:04:56.359447Z",
     "shell.execute_reply.started": "2021-10-29T21:04:56.207280Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Mean Percentage Error - applied on HYPERPARAMETER FINE TUNING\n",
    "def mean_percentage_error(y, yhat):\n",
    "    return np.mean( ( y - yhat ) / y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a technique that uses the training set to perform a fit/predict loop. The set is sliced into \"K\" parts. The K-1 slices are used for training and the remaining slice is used for testing. In each loop the test slice is replaced by one of the training ones and vice versa, the project metrics are applied to identify the performance of the generalization, in the end it provides an average of the calculated metrics for each iteration. It has a high computational cost!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T20:45:31.223550Z",
     "start_time": "2020-02-25T20:45:31.053473Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-29T21:04:56.366452Z",
     "iopub.status.busy": "2021-10-29T21:04:56.365809Z",
     "iopub.status.idle": "2021-10-29T21:04:56.468144Z",
     "shell.execute_reply": "2021-10-29T21:04:56.467444Z",
     "shell.execute_reply.started": "2021-10-29T21:04:56.366371Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cross_validation( x_training, kfold, model_name, model, verbose=False ):\n",
    "    mae_list = []\n",
    "    mape_list = []\n",
    "    rmse_list = []\n",
    "    for k in reversed( range( 1, kfold+1 ) ):\n",
    "        if verbose:\n",
    "            print( '\\nKFold Number: {}'.format( k ) )\n",
    "        # start and end date for validation \n",
    "        validation_start_date = x_training['date'].max() - datetime.timedelta( days=k*6*7)\n",
    "        validation_end_date = x_training['date'].max() - datetime.timedelta( days=(k-1)*6*7)\n",
    "\n",
    "        # filtering dataset\n",
    "        training = x_training[x_training['date'] < validation_start_date]\n",
    "        validation = x_training[(x_training['date'] >= validation_start_date) & (x_training['date'] <= validation_end_date)]\n",
    "\n",
    "        # training and validation dataset\n",
    "        # training\n",
    "        xtraining = training.drop( ['date', 'sales'], axis=1 ) \n",
    "        ytraining = training['sales']\n",
    "\n",
    "        # validation\n",
    "        xvalidation = validation.drop( ['date', 'sales'], axis=1 )\n",
    "        yvalidation = validation['sales']\n",
    "\n",
    "        # model\n",
    "        m = model.fit( xtraining, ytraining )\n",
    "\n",
    "        # prediction\n",
    "        yhat = m.predict( xvalidation )\n",
    "\n",
    "        # performance\n",
    "        m_result = ml_error( model_name, np.expm1( yvalidation ), np.expm1( yhat ) )\n",
    "\n",
    "        # store performance of each kfold iteration\n",
    "        mae_list.append(  m_result['MAE'] )\n",
    "        mape_list.append( m_result['MAPE%'] )\n",
    "        rmse_list.append( m_result['RMSE'] )\n",
    "\n",
    "    return pd.DataFrame( {'Model Name': model_name,\n",
    "                          'MAE CV': np.round( np.mean( mae_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( mae_list ), 2 ).astype( str ),\n",
    "                          'MAPE CV': np.round( np.mean( mape_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( mape_list ), 2 ).astype( str ),\n",
    "                          'RMSE CV': np.round( np.mean( rmse_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( rmse_list ), 2 ).astype( str ) }, index=[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabulate ML Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T00:57:46.388253Z",
     "start_time": "2020-07-14T00:57:46.362323Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-29T21:04:56.469196Z",
     "iopub.status.busy": "2021-10-29T21:04:56.468965Z",
     "iopub.status.idle": "2021-10-29T21:04:56.608019Z",
     "shell.execute_reply": "2021-10-29T21:04:56.605348Z",
     "shell.execute_reply.started": "2021-10-29T21:04:56.469171Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Error summary function - applied on MACHINE LEARNING MODELLING\n",
    "def ml_error( model_name, y, yhat ):\n",
    "    mae = mean_absolute_error( y, yhat)\n",
    "    mape = mean_absolute_percentage_error( y, yhat)\n",
    "    rmse = np.sqrt(mean_squared_error(y, yhat))\n",
    "    \n",
    "    return pd.DataFrame( { 'Model Name' : model_name,\n",
    "                           'MAE'  : mae,\n",
    "                           'MAPE%': mape,\n",
    "                           'RMSE' : rmse}, index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:04:56.611569Z",
     "iopub.status.busy": "2021-10-29T21:04:56.610808Z",
     "iopub.status.idle": "2021-10-29T21:04:56.789340Z",
     "shell.execute_reply": "2021-10-29T21:04:56.786957Z",
     "shell.execute_reply.started": "2021-10-29T21:04:56.611482Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_data ( df, name ):\n",
    "    global intdata\n",
    "    with open( intdata + name, 'wb' ) as f:\n",
    "        pickle.dump( df , f )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:04:56.792843Z",
     "iopub.status.busy": "2021-10-29T21:04:56.792218Z",
     "iopub.status.idle": "2021-10-29T21:04:56.895449Z",
     "shell.execute_reply": "2021-10-29T21:04:56.894575Z",
     "shell.execute_reply.started": "2021-10-29T21:04:56.792762Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data ( name ):\n",
    "    global intdata\n",
    "    with open( intdata + name, 'rb') as f:\n",
    "        return pickle.load( f )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:04:56.898454Z",
     "iopub.status.busy": "2021-10-29T21:04:56.897848Z",
     "iopub.status.idle": "2021-10-29T21:04:57.008812Z",
     "shell.execute_reply": "2021-10-29T21:04:57.006389Z",
     "shell.execute_reply.started": "2021-10-29T21:04:56.898411Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model ( model , name ):\n",
    "    global modelpath\n",
    "    with open( modelpath + name, 'wb' ) as f:\n",
    "        pickle.dump( model , f )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:04:57.012431Z",
     "iopub.status.busy": "2021-10-29T21:04:57.011757Z",
     "iopub.status.idle": "2021-10-29T21:04:57.168165Z",
     "shell.execute_reply": "2021-10-29T21:04:57.165780Z",
     "shell.execute_reply.started": "2021-10-29T21:04:57.012317Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model ( name ):\n",
    "    global modelpath\n",
    "    with open( modelpath + name, 'rb') as f:\n",
    "        return pickle.load( f )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set files enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:04:57.172421Z",
     "iopub.status.busy": "2021-10-29T21:04:57.171491Z",
     "iopub.status.idle": "2021-10-29T21:04:57.272604Z",
     "shell.execute_reply": "2021-10-29T21:04:57.271906Z",
     "shell.execute_reply.started": "2021-10-29T21:04:57.172294Z"
    }
   },
   "outputs": [],
   "source": [
    "absolute_path = '/home/rodrigo/Projetos/Comunidade_DS/data_science_producao/'\n",
    "rawdata = '../data/raw/'\n",
    "intdata = '../data/interim/'\n",
    "modelpath = '../models/'\n",
    "seed = 17\n",
    "rawdatafile = 'rossmann_sales.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Initialization Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T22:42:41.989939Z",
     "start_time": "2021-10-26T22:42:41.986790Z"
    },
    "hidden": true
   },
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T22:39:14.431932Z",
     "start_time": "2021-10-26T22:39:14.422008Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv( rawdata+rawdatafile, low_memory=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data( df_raw, 'df_raw.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# DESCRICAO DOS DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:25:27.679748Z",
     "start_time": "2020-01-08T11:25:27.215031Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1 = load_data( 'df_raw.pkl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:25:27.697235Z",
     "start_time": "2020-01-08T11:25:27.686305Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols_old = ['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', \n",
    "            'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
    "            'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
    "\n",
    "snakecase = lambda x: inflection.underscore( x )\n",
    "\n",
    "cols_new = list( map( snakecase, cols_old ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:25:27.697235Z",
     "start_time": "2020-01-08T11:25:27.686305Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# rename\n",
    "df1.columns = cols_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cols_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model( cols_new, 'cols_new.pkl' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:25:27.711998Z",
     "start_time": "2020-01-08T11:25:27.704893Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print( 'Number of Rows: {}'.format( df1.shape[0] ) )\n",
    "print( 'Number of Cols: {}'.format( df1.shape[1] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:25:27.937245Z",
     "start_time": "2020-01-08T11:25:27.716659Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1['date'] = pd.to_datetime( df1['date'] )\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Check NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:25:28.252036Z",
     "start_time": "2020-01-08T11:25:27.943358Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Fillout NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:25:28.408700Z",
     "start_time": "2020-01-08T11:25:28.261107Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1.sample(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:28:17.108337Z",
     "start_time": "2020-01-08T11:25:28.420028Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#competition_distance        \n",
    "df1['competition_distance'] = df1['competition_distance'].apply( lambda x: 100000.0 if math.isnan( x ) else x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:28:17.108337Z",
     "start_time": "2020-01-08T11:25:28.420028Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#competition_open_since_month\n",
    "df1['competition_open_since_month'] = df1.apply( lambda x: x['date'].month if math.isnan( x['competition_open_since_month'] ) else x['competition_open_since_month'], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:28:17.108337Z",
     "start_time": "2020-01-08T11:25:28.420028Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#competition_open_since_year \n",
    "df1['competition_open_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan( x['competition_open_since_year'] ) else x['competition_open_since_year'], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:28:17.108337Z",
     "start_time": "2020-01-08T11:25:28.420028Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#promo2_since_week           \n",
    "df1['promo2_since_week'] = df1.apply( lambda x: x['date'].week if math.isnan( x['promo2_since_week'] ) else x['promo2_since_week'], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:28:17.108337Z",
     "start_time": "2020-01-08T11:25:28.420028Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#promo2_since_year           \n",
    "df1['promo2_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan( x['promo2_since_year'] ) else x['promo2_since_year'], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:28:17.108337Z",
     "start_time": "2020-01-08T11:25:28.420028Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#promo_interval              \n",
    "month_map = {1: 'Jan',  2: 'Fev',  3: 'Mar',  4: 'Apr',  5: 'May',  6: 'Jun',  7: 'Jul',  8: 'Aug',  9: 'Sep',  10: 'Oct', 11: 'Nov', 12: 'Dec'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:28:17.108337Z",
     "start_time": "2020-01-08T11:25:28.420028Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1['promo_interval'].fillna(0, inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:28:17.108337Z",
     "start_time": "2020-01-08T11:25:28.420028Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1['month_map'] = df1['date'].dt.month.map( month_map )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:28:17.108337Z",
     "start_time": "2020-01-08T11:25:28.420028Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1['is_promo'] = df1[['promo_interval', 'month_map']].apply( lambda x: 0 if x['promo_interval'] == 0 else 1 if x['month_map'] in x['promo_interval'].split( ',' ) else 0, axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:28:17.466106Z",
     "start_time": "2020-01-08T11:28:17.111460Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.sample(10).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Change Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:28:17.540618Z",
     "start_time": "2020-01-08T11:28:17.470520Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# competiton\n",
    "df1['competition_open_since_month'] = df1['competition_open_since_month'].astype( int )\n",
    "df1['competition_open_since_year'] = df1['competition_open_since_year'].astype( int )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:28:17.540618Z",
     "start_time": "2020-01-08T11:28:17.470520Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# promo2\n",
    "df1['promo2_since_week'] = df1['promo2_since_week'].astype( int )\n",
    "df1['promo2_since_year'] = df1['promo2_since_year'].astype( int )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:28:17.789458Z",
     "start_time": "2020-01-08T11:28:17.546967Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_attributes = df1.select_dtypes( include=['int64', 'float64'] )\n",
    "cat_attributes = df1.select_dtypes( exclude=['int64', 'float64', 'datetime64[ns]'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Numerical Atributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1st_order_stats = descriptive_stats_1st_order(num_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1st_order_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:28:23.825369Z",
     "start_time": "2020-01-08T11:28:22.646498Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot( df1['competition_distance'], kde=False, bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T11:26:41.736121Z",
     "start_time": "2019-11-10T11:26:41.732986Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Categorical Atributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:28:24.076642Z",
     "start_time": "2020-01-08T11:28:23.829675Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cat_attributes.apply( lambda x: x.unique().shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:28:25.410494Z",
     "start_time": "2020-01-08T11:28:24.081464Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aux = df1[(df1['state_holiday'] != '0') & (df1['sales'] > 0)]\n",
    "\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.boxplot( x='state_holiday', y='sales', data=aux )\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.boxplot( x='store_type', y='sales', data=aux )\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "sns.boxplot( x='assortment', y='sales', data=aux );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data ( df1, 'df1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "toc-hr-collapsed": true
   },
   "source": [
    "# FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:28:25.536405Z",
     "start_time": "2020-01-08T11:28:25.414860Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2 = load_data ( 'df1.pkl' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Mapa Mental de Hipoteses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:28:25.553246Z",
     "start_time": "2020-01-08T11:28:25.540395Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Image( '../images/MindMapHypothesis.png' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Criacao das Hipoteses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Hipoteses Loja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**1.** Lojas com número maior de funcionários deveriam vender mais.\n",
    "\n",
    "**2.** Lojas com maior capacidade de estoque deveriam vender mais.\n",
    "\n",
    "**3.** Lojas com maior porte deveriam vender mais.\n",
    "\n",
    "**4.** Lojas com maior sortimentos deveriam vender mais.\n",
    "\n",
    "**5.** Lojas com competidores mais próximos deveriam vender menos.\n",
    "\n",
    "**6.** Lojas com competidores à mais tempo deveriam vendem mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Hipoteses Produto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:22:20.284469Z",
     "start_time": "2019-11-16T21:22:20.236577Z"
    },
    "hidden": true
   },
   "source": [
    "**1.** Lojas que investem mais em Marketing deveriam vender mais.\n",
    "\n",
    "**2.** Lojas com maior exposição de produto deveriam vender mais.\n",
    "\n",
    "**3.** Lojas com produtos com preço menor deveriam vender mais.\n",
    "\n",
    "**5.** Lojas com promoções mais agressivas ( descontos maiores ), deveriam vender mais.\n",
    "\n",
    "**6.** Lojas com promoções ativas por mais tempo deveriam vender mais.\n",
    "\n",
    "**7.** Lojas com mais dias de promoção deveriam vender mais.\n",
    "\n",
    "**8.** Lojas com mais promoções consecutivas deveriam vender mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Hipoteses Tempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:24:09.377189Z",
     "start_time": "2019-11-16T21:24:09.339135Z"
    },
    "hidden": true
   },
   "source": [
    "**1.** Lojas abertas durante o feriado de Natal deveriam vender mais.\n",
    "\n",
    "**2.** Lojas deveriam vender mais ao longo dos anos.\n",
    "\n",
    "**3.** Lojas deveriam vender mais no segundo semestre do ano.\n",
    "\n",
    "**4.** Lojas deveriam vender mais depois do dia 10 de cada mês.\n",
    "\n",
    "**5.** Lojas deveriam vender menos aos finais de semana.\n",
    "\n",
    "**6.** Lojas deveriam vender menos durante os feriados escolares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Lista Final de Hipóteses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**1.** Lojas com maior sortimentos deveriam vender mais.\n",
    "\n",
    "**2.** Lojas com competidores mais próximos deveriam vender menos.\n",
    "\n",
    "**3.** Lojas com competidores à mais tempo deveriam vendem mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**4.** Lojas com promoções ativas por mais tempo deveriam vender mais.\n",
    "\n",
    "**5.** Lojas com mais dias de promoção deveriam vender mais.\n",
    "\n",
    "**7.** Lojas com mais promoções consecutivas deveriam vender mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:33:04.092534Z",
     "start_time": "2019-11-16T21:33:04.074217Z"
    },
    "hidden": true
   },
   "source": [
    "**8.** Lojas abertas durante o feriado de Natal deveriam vender mais.\n",
    "\n",
    "**9.** Lojas deveriam vender mais ao longo dos anos.\n",
    "\n",
    "**10.** Lojas deveriam vender mais no segundo semestre do ano.\n",
    "\n",
    "**11.** Lojas deveriam vender mais depois do dia 10 de cada mês.\n",
    "\n",
    "**12.** Lojas deveriam vender menos aos finais de semana.\n",
    "\n",
    "**13.** Lojas deveriam vender menos durante os feriados escolares.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:29:42.472423Z",
     "start_time": "2020-01-08T11:28:25.558653Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# year\n",
    "df2['year'] = df2['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:29:42.472423Z",
     "start_time": "2020-01-08T11:28:25.558653Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# month\n",
    "df2['month'] = df2['date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:29:42.472423Z",
     "start_time": "2020-01-08T11:28:25.558653Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# day\n",
    "df2['day'] = df2['date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:29:42.472423Z",
     "start_time": "2020-01-08T11:28:25.558653Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# week of year\n",
    "df2['week_of_year'] = df2['date'].dt.weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:29:42.472423Z",
     "start_time": "2020-01-08T11:28:25.558653Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# year week\n",
    "df2['year_week'] = df2['date'].dt.strftime( '%Y-%W' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:29:42.472423Z",
     "start_time": "2020-01-08T11:28:25.558653Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# competition since\n",
    "df2['competition_since'] = df2.apply( lambda x: datetime.datetime( year=x['competition_open_since_year'], month=x['competition_open_since_month'],day=1 ), axis=1 )\n",
    "df2['competition_time_month'] = ( ( df2['date'] - df2['competition_since'] )/30 ).apply( lambda x: x.days ).astype( int )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:29:42.472423Z",
     "start_time": "2020-01-08T11:28:25.558653Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# promo since\n",
    "df2['promo_since'] = df2['promo2_since_year'].astype( str ) + '-' + df2['promo2_since_week'].astype( str )\n",
    "df2['promo_since'] = df2['promo_since'].apply( lambda x: datetime.datetime.strptime( x + '-1', '%Y-%W-%w' ) - datetime.timedelta( days=7 ) )\n",
    "df2['promo_time_week'] = ( ( df2['date'] - df2['promo_since'] )/7 ).apply( lambda x: x.days ).astype( int )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:29:42.472423Z",
     "start_time": "2020-01-08T11:28:25.558653Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# assortment\n",
    "df2['assortment'] = df2['assortment'].apply( lambda x: 'basic' if x == 'a' else 'extra' if x == 'b' else 'extended' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:29:42.472423Z",
     "start_time": "2020-01-08T11:28:25.558653Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# state holiday\n",
    "df2['state_holiday'] = df2['state_holiday'].apply( lambda x: 'public_holiday' if x == 'a' else 'easter_holiday' if x == 'b' else 'christmas' if x == 'c' else 'regular_day' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data ( df2, 'df2.pkl' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "toc-hr-collapsed": true
   },
   "source": [
    "# FILTRAGEM DE VARIÁVEIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:29:42.881713Z",
     "start_time": "2020-01-08T11:29:42.475296Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df3 = load_data ( 'df2.pkl' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Filtragem das Linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:29:43.097079Z",
     "start_time": "2020-01-08T11:29:42.884453Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df3 = df3[(df3['open'] != 0) & (df3['sales'] > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Selecao das Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:29:43.243109Z",
     "start_time": "2020-01-08T11:29:43.100420Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols_drop = ['customers', 'open', 'promo_interval', 'month_map']\n",
    "df3 = df3.drop( cols_drop, axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data( df3, 'df3.pkl' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# ANALISE EXPLORATORIA DOS DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:29:43.308003Z",
     "start_time": "2020-01-08T11:29:43.246115Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df4 = load_data( 'df3.pkl' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Analise Univariada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "hide_input": true
   },
   "source": [
    "### Response Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:29:44.371855Z",
     "start_time": "2020-01-08T11:29:43.315474Z"
    },
    "hidden": true,
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot( df4['sales'], kde=False  );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Numerical Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:29:50.257037Z",
     "start_time": "2020-01-08T11:29:44.380842Z"
    },
    "hidden": true,
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_attributes.hist( bins=50 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "hide_input": true
   },
   "source": [
    "### Categorical Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:30:12.592471Z",
     "start_time": "2020-01-08T11:29:50.264017Z"
    },
    "hidden": true,
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# state_holiday\n",
    "plt.subplot( 3, 2, 1 )\n",
    "a = df4[df4['state_holiday'] != 'regular_day']\n",
    "sns.countplot( a['state_holiday'] )\n",
    "\n",
    "plt.subplot( 3, 2, 2 )\n",
    "sns.kdeplot( df4[df4['state_holiday'] == 'public_holiday']['sales'], label='public_holiday', shade=True )\n",
    "sns.kdeplot( df4[df4['state_holiday'] == 'easter_holiday']['sales'], label='easter_holiday', shade=True )\n",
    "sns.kdeplot( df4[df4['state_holiday'] == 'christmas']['sales'], label='christmas', shade=True )\n",
    "\n",
    "# store_type\n",
    "plt.subplot( 3, 2, 3 )\n",
    "sns.countplot( df4['store_type'] )\n",
    "\n",
    "plt.subplot( 3, 2, 4 )\n",
    "sns.kdeplot( df4[df4['store_type'] == 'a']['sales'], label='a', shade=True )\n",
    "sns.kdeplot( df4[df4['store_type'] == 'b']['sales'], label='b', shade=True )\n",
    "sns.kdeplot( df4[df4['store_type'] == 'c']['sales'], label='c', shade=True )\n",
    "sns.kdeplot( df4[df4['store_type'] == 'd']['sales'], label='d', shade=True )\n",
    "\n",
    "# assortment\n",
    "plt.subplot( 3, 2, 5 )\n",
    "sns.countplot( df4['assortment'] )\n",
    "\n",
    "plt.subplot( 3, 2, 6 )\n",
    "sns.kdeplot( df4[df4['assortment'] == 'extended']['sales'], label='extended', shade=True )\n",
    "sns.kdeplot( df4[df4['assortment'] == 'basic']['sales'], label='basic', shade=True )\n",
    "sns.kdeplot( df4[df4['assortment'] == 'extra']['sales'], label='extra', shade=True );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Analise Bivariada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "hide_input": true
   },
   "source": [
    "### **H1.** Lojas com maior sortimentos deveriam vender mais.\n",
    "**FALSA** Lojas com MAIOR SORTIMENTO vendem MENOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:30:15.273708Z",
     "start_time": "2020-01-08T11:30:12.595344Z"
    },
    "hidden": true,
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['assortment', 'sales']].groupby( 'assortment' ).sum().reset_index()\n",
    "sns.barplot( x='assortment', y='sales', data=aux1 );\n",
    "\n",
    "aux2 = df4[['year_week', 'assortment', 'sales']].groupby( ['year_week','assortment'] ).sum().reset_index()\n",
    "aux2.pivot( index='year_week', columns='assortment', values='sales' ).plot()\n",
    "\n",
    "aux3 = aux2[aux2['assortment'] == 'extra']\n",
    "aux3.pivot( index='year_week', columns='assortment', values='sales' ).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### **H2.** Lojas com competidores mais próximos deveriam vender menos.\n",
    "**FALSA** Lojas com COMPETIDORES MAIS PROXIMOS vendem MAIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:30:17.216099Z",
     "start_time": "2020-01-08T11:30:15.277961Z"
    },
    "hidden": true,
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['competition_distance', 'sales']].groupby( 'competition_distance' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.scatterplot( x ='competition_distance', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "bins = list( np.arange( 0, 20000, 1000) )\n",
    "aux1['competition_distance_binned'] = pd.cut( aux1['competition_distance'], bins=bins )\n",
    "aux2 = aux1[['competition_distance_binned', 'sales']].groupby( 'competition_distance_binned' ).sum().reset_index()\n",
    "sns.barplot( x='competition_distance_binned', y='sales', data=aux2 );\n",
    "plt.xticks( rotation=90 );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "x = sns.heatmap( aux1.corr( method='pearson' ), annot=True );\n",
    "bottom, top = x.get_ylim()\n",
    "x.set_ylim( bottom+0.5, top-0.5 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### **H3.** Lojas com competidores à mais tempo deveriam vendem mais.\n",
    "**FALSE** Lojas com COMPETIDORES À MAIS TEMPO vendem MENOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:30:24.963868Z",
     "start_time": "2020-01-08T11:30:17.220615Z"
    },
    "hidden": true,
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.subplot( 1, 3, 1 )\n",
    "aux1 = df4[['competition_time_month', 'sales']].groupby( 'competition_time_month' ).sum().reset_index()\n",
    "aux2 = aux1[( aux1['competition_time_month'] < 120 ) & ( aux1['competition_time_month'] != 0 )]\n",
    "sns.barplot( x='competition_time_month', y='sales', data=aux2 );\n",
    "plt.xticks( rotation=90 );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.regplot( x='competition_time_month', y='sales', data=aux2 );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "x = sns.heatmap( aux1.corr( method='pearson'), annot=True );\n",
    "bottom, top = x.get_ylim()\n",
    "x.set_ylim( bottom+0.5, top-0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### **H4.** Lojas com promoções ativas por mais tempo deveriam vender mais.\n",
    "**FALSA** Lojas com promocoes ativas por mais tempo vendem menos, depois de um certo periodo de promocao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:30:45.955054Z",
     "start_time": "2020-01-08T11:30:24.968137Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['promo_time_week', 'sales']].groupby( 'promo_time_week').sum().reset_index()\n",
    "\n",
    "grid = GridSpec( 2, 3 )\n",
    "\n",
    "plt.subplot( grid[0,0] )\n",
    "aux2 = aux1[aux1['promo_time_week'] > 0] # promo extendido\n",
    "sns.barplot( x='promo_time_week', y='sales', data=aux2 );\n",
    "plt.xticks( rotation=90 );\n",
    "\n",
    "plt.subplot( grid[0,1] )\n",
    "sns.regplot( x='promo_time_week', y='sales', data=aux2 );\n",
    "\n",
    "plt.subplot( grid[1,0] )\n",
    "aux3 = aux1[aux1['promo_time_week'] < 0] # promo regular\n",
    "sns.barplot( x='promo_time_week', y='sales', data=aux3 );\n",
    "plt.xticks( rotation=90 );\n",
    "\n",
    "plt.subplot( grid[1,1] )\n",
    "sns.regplot( x='promo_time_week', y='sales', data=aux3 );\n",
    "\n",
    "plt.subplot( grid[:,2] )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### <s>**H5.** Lojas com mais dias de promoção deveriam vender mais.</s>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### **H7.** Lojas com mais promoções consecutivas deveriam vender mais.\n",
    "**FALSA** Lojas com mais promocoes consecutivas vendem menos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:30:46.074165Z",
     "start_time": "2020-01-08T11:30:45.958424Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "df4[['promo', 'promo2', 'sales']].groupby( ['promo', 'promo2'] ).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:30:47.178833Z",
     "start_time": "2020-01-08T11:30:46.078914Z"
    },
    "hidden": true,
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[( df4['promo'] == 1 ) & ( df4['promo2'] == 1 )][['year_week', 'sales']].groupby( 'year_week' ).sum().reset_index()\n",
    "ax = aux1.plot()\n",
    "\n",
    "aux2 = df4[( df4['promo'] == 1 ) & ( df4['promo2'] == 0 )][['year_week', 'sales']].groupby( 'year_week' ).sum().reset_index()\n",
    "aux2.plot( ax=ax )\n",
    "\n",
    "ax.legend( labels=['Tradicional & Extendida', 'Extendida']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:33:04.092534Z",
     "start_time": "2019-11-16T21:33:04.074217Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### **H8.** Lojas abertas durante o feriado de Natal deveriam vender mais.\n",
    "**FALSA** Lojas abertas durante o feriado do Natal vendem menos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:30:48.402106Z",
     "start_time": "2020-01-08T11:30:47.182245Z"
    },
    "hidden": true,
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aux = df4[df4['state_holiday'] != 'regular_day']\n",
    "\n",
    "plt.subplot( 1, 2, 1 )\n",
    "aux1 = aux[['state_holiday', 'sales']].groupby( 'state_holiday' ).sum().reset_index()\n",
    "sns.barplot( x='state_holiday', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 2, 2 )\n",
    "aux2 = aux[['year', 'state_holiday', 'sales']].groupby( ['year', 'state_holiday'] ).sum().reset_index()\n",
    "sns.barplot( x='year', y='sales', hue='state_holiday', data=aux2 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:33:04.092534Z",
     "start_time": "2019-11-16T21:33:04.074217Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### **H9.** Lojas deveriam vender mais ao longo dos anos.\n",
    "**FALSA** Lojas vendem menos ao longo dos anos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:30:49.828346Z",
     "start_time": "2020-01-08T11:30:48.408600Z"
    },
    "hidden": true,
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['year', 'sales']].groupby( 'year' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.barplot( x='year', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.regplot( x='year', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:33:04.092534Z",
     "start_time": "2019-11-16T21:33:04.074217Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### **H10.** Lojas deveriam vender mais no segundo semestre do ano.\n",
    "**FALSA** Lojas vendem menos no segundo semestre do ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:30:51.452892Z",
     "start_time": "2020-01-08T11:30:49.832424Z"
    },
    "hidden": true,
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['month', 'sales']].groupby( 'month' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.barplot( x='month', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.regplot( x='month', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:33:04.092534Z",
     "start_time": "2019-11-16T21:33:04.074217Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### **H11.** Lojas deveriam vender mais depois do dia 10 de cada mês.\n",
    "**VERDADEIRA** Lojas vendem mais depois do dia 10 de cada mes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:30:53.682300Z",
     "start_time": "2020-01-08T11:30:51.457208Z"
    },
    "hidden": true,
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['day', 'sales']].groupby( 'day' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 2, 2, 1 )\n",
    "sns.barplot( x='day', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 2, 2, 2 )\n",
    "sns.regplot( x='day', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 2, 2, 3 )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );\n",
    "\n",
    "aux1['before_after'] = aux1['day'].apply( lambda x: 'before_10_days' if x <= 10 else 'after_10_days' )\n",
    "aux2 =aux1[['before_after', 'sales']].groupby( 'before_after' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 2, 2, 4 )\n",
    "sns.barplot( x='before_after', y='sales', data=aux2 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:33:04.092534Z",
     "start_time": "2019-11-16T21:33:04.074217Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### **H12.** Lojas deveriam vender menos aos finais de semana.\n",
    "**VERDADEIRA** Lojas vendem menos nos final de semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:30:55.243417Z",
     "start_time": "2020-01-08T11:30:53.686512Z"
    },
    "hidden": true,
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['day_of_week', 'sales']].groupby( 'day_of_week' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.barplot( x='day_of_week', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.regplot( x='day_of_week', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-16T21:33:04.092534Z",
     "start_time": "2019-11-16T21:33:04.074217Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### **H13.** Lojas deveriam vender menos durante os feriados escolares.\n",
    "**VERDADEIRA** Lojas vendem menos durante os feriadso escolares, except os meses de Julho e Agosto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:30:56.549426Z",
     "start_time": "2020-01-08T11:30:55.247604Z"
    },
    "hidden": true,
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['school_holiday', 'sales']].groupby( 'school_holiday' ).sum().reset_index()\n",
    "plt.subplot( 2, 1, 1 )\n",
    "sns.barplot( x='school_holiday', y='sales', data=aux1 );\n",
    "\n",
    "aux2 = df4[['month', 'school_holiday', 'sales']].groupby( ['month','school_holiday'] ).sum().reset_index()\n",
    "plt.subplot( 2, 1, 2 )\n",
    "sns.barplot( x='month', y='sales', hue='school_holiday', data=aux2 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Resumo das Hipoteses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:30:56.591591Z",
     "start_time": "2020-01-08T11:30:56.565981Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "tab =[['Hipoteses', 'Conclusao', 'Relevancia'],\n",
    "      ['H1', 'Falsa', 'Baixa'],  \n",
    "      ['H2', 'Falsa', 'Media'],  \n",
    "      ['H3', 'Falsa', 'Media'],\n",
    "      ['H4', 'Falsa', 'Baixa'],\n",
    "      ['H5', '-', '-'],\n",
    "      ['H7', 'Falsa', 'Baixa'],\n",
    "      ['H8', 'Falsa', 'Media'],\n",
    "      ['H9', 'Falsa', 'Alta'],\n",
    "      ['H10', 'Falsa', 'Alta'],\n",
    "      ['H11', 'Verdadeira', 'Alta'],\n",
    "      ['H12', 'Verdadeira', 'Alta'],\n",
    "      ['H13', 'Verdadeira', 'Baixa'],\n",
    "     ]  \n",
    "print( tabulate( tab, headers='firstrow' ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Analise Multivariada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Numerical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:30:59.271969Z",
     "start_time": "2020-01-08T11:30:56.620359Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "correlation = num_attributes.corr( method='pearson' )\n",
    "sns.heatmap( correlation, annot=True );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:31:01.323418Z",
     "start_time": "2020-01-08T11:30:59.274501Z"
    },
    "hidden": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# only categorical data\n",
    "a = df4.select_dtypes( include='object' )\n",
    "\n",
    "# Calculate cramer V\n",
    "a1 = cramer_v( a['state_holiday'], a['state_holiday'] )\n",
    "a2 = cramer_v( a['state_holiday'], a['store_type'] )\n",
    "a3 = cramer_v( a['state_holiday'], a['assortment'] )\n",
    "\n",
    "a4 = cramer_v( a['store_type'], a['state_holiday'] )\n",
    "a5 = cramer_v( a['store_type'], a['store_type'] )\n",
    "a6 = cramer_v( a['store_type'], a['assortment'] )\n",
    "\n",
    "a7 = cramer_v( a['assortment'], a['state_holiday'] )\n",
    "a8 = cramer_v( a['assortment'], a['store_type'] )\n",
    "a9 = cramer_v( a['assortment'], a['assortment'] )\n",
    "\n",
    "# Final dataset\n",
    "d = pd.DataFrame( {'state_holiday': [a1, a2, a3], \n",
    "               'store_type': [a4, a5, a6],\n",
    "               'assortment': [a7, a8, a9]  })\n",
    "d = d.set_index( d.columns )\n",
    "\n",
    "sns.heatmap( d, annot=True );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_data( df4, 'df4.pkl' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "toc-hr-collapsed": true
   },
   "source": [
    "# DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T11:18:43.798074Z",
     "start_time": "2020-01-11T11:18:43.610975Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df5 = load_data( 'df4.pkl' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Normalizacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T11:18:45.931421Z",
     "start_time": "2020-01-11T11:18:45.438957Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rs = RobustScaler()\n",
    "mms = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T11:18:45.931421Z",
     "start_time": "2020-01-11T11:18:45.438957Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# competition distance\n",
    "df5['competition_distance'] = rs.fit_transform( df5[['competition_distance']].values )\n",
    "save_model( rs, 'competition_distance_scaler.pkl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T11:18:45.931421Z",
     "start_time": "2020-01-11T11:18:45.438957Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# competition time month\n",
    "df5['competition_time_month'] = rs.fit_transform( df5[['competition_time_month']].values )\n",
    "save_model( rs, 'competition_time_month_scaler.pkl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T11:18:45.931421Z",
     "start_time": "2020-01-11T11:18:45.438957Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# promo time week\n",
    "df5['promo_time_week'] = mms.fit_transform( df5[['promo_time_week']].values )\n",
    "save_model( rs, 'promo_time_week_scaler.pkl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T11:18:45.931421Z",
     "start_time": "2020-01-11T11:18:45.438957Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# year\n",
    "df5['year'] = mms.fit_transform( df5[['year']].values )\n",
    "save_model( mms, 'year_scaler.pkl' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Transformacao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T11:07:11.824502Z",
     "start_time": "2020-01-11T11:07:09.421858Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# state_holiday - One Hot Encoding\n",
    "df5 = pd.get_dummies( df5, prefix=['state_holiday'], columns=['state_holiday'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T11:07:11.824502Z",
     "start_time": "2020-01-11T11:07:09.421858Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# store_type - Label Encoding\n",
    "le = LabelEncoder()\n",
    "df5['store_type'] = le.fit_transform( df5['store_type'] )\n",
    "save_model( le, 'store_type_scaler.pkl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T11:07:11.824502Z",
     "start_time": "2020-01-11T11:07:09.421858Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# assortment - Ordinal Encoding\n",
    "assortment_dict = {'basic': 1,  'extra': 2, 'extended': 3}\n",
    "df5['assortment'] = df5['assortment'].map( assortment_dict )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Response Variable Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:31:02.335057Z",
     "start_time": "2020-01-08T11:31:02.304060Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df5['sales'] = np.log1p( df5['sales'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Nature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:31:12.316198Z",
     "start_time": "2020-01-08T11:31:02.339172Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# day of week\n",
    "df5['day_of_week_sin'] = df5['day_of_week'].apply( lambda x: np.sin( x * ( 2. * np.pi/7 ) ) )\n",
    "df5['day_of_week_cos'] = df5['day_of_week'].apply( lambda x: np.cos( x * ( 2. * np.pi/7 ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:31:12.316198Z",
     "start_time": "2020-01-08T11:31:02.339172Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# month\n",
    "df5['month_sin'] = df5['month'].apply( lambda x: np.sin( x * ( 2. * np.pi/12 ) ) )\n",
    "df5['month_cos'] = df5['month'].apply( lambda x: np.cos( x * ( 2. * np.pi/12 ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:31:12.316198Z",
     "start_time": "2020-01-08T11:31:02.339172Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# day \n",
    "df5['day_sin'] = df5['day'].apply( lambda x: np.sin( x * ( 2. * np.pi/30 ) ) )\n",
    "df5['day_cos'] = df5['day'].apply( lambda x: np.cos( x * ( 2. * np.pi/30 ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:31:12.316198Z",
     "start_time": "2020-01-08T11:31:02.339172Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# week of year\n",
    "df5['week_of_year_sin'] = df5['week_of_year'].apply( lambda x: np.sin( x * ( 2. * np.pi/52 ) ) )\n",
    "df5['week_of_year_cos'] = df5['week_of_year'].apply( lambda x: np.cos( x * ( 2. * np.pi/52 ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data( df5, 'df5.pkl' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:31:12.685886Z",
     "start_time": "2020-01-08T11:31:12.318850Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df6 = df5.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l0, c = df6.shape\n",
    "print('df6 have {} Lines and {} Columns\\n'.format( l0 , c ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Split dataframe into training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:31:12.821771Z",
     "start_time": "2020-01-08T11:31:12.689701Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols_drop = ['week_of_year', 'day', 'month', 'day_of_week', 'promo_since', 'competition_since', 'year_week' ]\n",
    "df6 = df6.drop( cols_drop, axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:31:12.927069Z",
     "start_time": "2020-01-08T11:31:12.824541Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# training dataset\n",
    "X_train = df6[df6['date'] < '2015-06-19']\n",
    "y_train = X_train['sales']\n",
    "\n",
    "l1, c = X_train.shape\n",
    "print('X_train have {} Lines and {} Columns\\n'.format( l1 , c ) )\n",
    "\n",
    "# test dataset\n",
    "X_test = df6[df6['date'] >= '2015-06-19']\n",
    "y_test = X_test['sales']\n",
    "\n",
    "l2, c = X_test.shape\n",
    "print('X_test have {} Lines and {} Columns\\n'.format( l2 , c ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print min and max date values\n",
    "print( 'Training Min Date: {}'.format( X_train['date'].min() ) )\n",
    "print( 'Training Max Date: {}\\n'.format( X_train['date'].max() ) )\n",
    "\n",
    "print( 'Test Min Date: {}'.format( X_test['date'].min() ) )\n",
    "print( 'Test Max Date: {}'.format( X_test['date'].max() ) )\n",
    "\n",
    "print(\"\\nSo, if df6 have {} lines, the sum of X_train and X_test is {} lines to ! ok ?\".format(l0, l1+l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model( X_train, 'X_train.pkl' )\n",
    "save_model( y_train, 'y_train.pkl' )\n",
    "save_model( X_test, 'X_test.pkl' )\n",
    "save_model( y_test, 'y_test.pkl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data( df6, 'df6.pkl' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Boruta as Feature Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:31:12.939239Z",
     "start_time": "2020-01-08T11:31:12.930752Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## training and test dataset for Boruta\n",
    "#X_train_n = X_train.drop( ['date', 'sales'], axis=1 ).values\n",
    "#y_train_n = y_train.values.ravel()\n",
    "#\n",
    "## define RandomForestRegressor\n",
    "#rf = RandomForestRegressor( n_jobs=-1 )\n",
    "#\n",
    "## define Boruta\n",
    "#boruta = BorutaPy( rf, n_estimators='auto', verbose=2, random_state=42 ).fit( X_train_n, y_train_n )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Best Features from Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:31:12.948660Z",
     "start_time": "2020-01-08T11:31:12.942455Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cols_selected = boruta.support_.tolist()\n",
    "#\n",
    "## best features\n",
    "#X_train_fs = X_train.drop( ['date', 'sales'], axis=1 )\n",
    "#cols_selected_boruta = X_train_fs.iloc[:, cols_selected].columns.to_list()\n",
    "#\n",
    "## not selected boruta\n",
    "#cols_not_selected_boruta = list( np.setdiff1d( X_train_fs.columns, cols_selected_boruta ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Manual Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:31:12.961627Z",
     "start_time": "2020-01-08T11:31:12.952511Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols_selected_boruta = [\n",
    "    'store',\n",
    "    'promo',\n",
    "    'store_type',\n",
    "    'assortment',\n",
    "    'competition_distance',\n",
    "    'competition_open_since_month',\n",
    "    'competition_open_since_year',\n",
    "    'promo2',\n",
    "    'promo2_since_week',\n",
    "    'promo2_since_year',\n",
    "    'competition_time_month',\n",
    "    'promo_time_week',\n",
    "    'day_of_week_sin',\n",
    "    'day_of_week_cos',\n",
    "    'month_sin',\n",
    "    'month_cos',\n",
    "    'day_sin',\n",
    "    'day_cos',\n",
    "    'week_of_year_sin',\n",
    "    'week_of_year_cos']\n",
    "\n",
    "# columns to add\n",
    "feat_to_add = ['date', 'sales']\n",
    "\n",
    "cols_selected_boruta_full = cols_selected_boruta.copy()\n",
    "cols_selected_boruta_full.extend( feat_to_add )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model( cols_selected_boruta, 'cols_selected_boruta.pkl' )\n",
    "save_model( cols_selected_boruta_full, 'cols_selected_boruta_full.pkl' )\n",
    "save_model( feat_to_add, 'feat_to_add.pkl' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# MACHINE LEARNING MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:05:49.519810Z",
     "iopub.status.busy": "2021-10-29T21:05:49.519543Z",
     "iopub.status.idle": "2021-10-29T21:05:51.647999Z",
     "shell.execute_reply": "2021-10-29T21:05:51.645596Z",
     "shell.execute_reply.started": "2021-10-29T21:05:49.519780Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = load_model( 'X_train.pkl' )\n",
    "y_train = load_model( 'y_train.pkl' )\n",
    "X_test = load_model( 'X_test.pkl' )\n",
    "y_test = load_model( 'y_test.pkl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_selected_boruta = load_model( 'cols_selected_boruta.pkl' )\n",
    "cols_selected_boruta_full = load_model( 'cols_selected_boruta_full.pkl' )\n",
    "feat_to_add = load_model( 'feat_to_add.pkl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:31:13.147248Z",
     "start_time": "2020-01-08T11:31:12.977711Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_train = X_train[ cols_selected_boruta ]\n",
    "x_test = X_test[ cols_selected_boruta ]\n",
    "\n",
    "# Time Series Data Preparation\n",
    "x_training = X_train[ cols_selected_boruta_full ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Average Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:31:13.225584Z",
     "start_time": "2020-01-08T11:31:13.150003Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux1 = x_test.copy()\n",
    "aux1['sales'] = y_test.copy()\n",
    "\n",
    "# prediction\n",
    "aux2 = aux1[['store', 'sales']].groupby( 'store' ).mean().reset_index().rename( columns={'sales': 'predictions'} )\n",
    "aux1 = pd.merge( aux1, aux2, how='left', on='store' )\n",
    "yhat_baseline = aux1['predictions']\n",
    "\n",
    "# performance\n",
    "baseline_result = ml_error( 'Average Model', np.expm1( y_test ), np.expm1( yhat_baseline ) )\n",
    "baseline_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:31:13.964969Z",
     "start_time": "2020-01-08T11:31:13.230103Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "lr = LinearRegression().fit( x_train, y_train )\n",
    "\n",
    "# prediction\n",
    "yhat_lr = lr.predict( x_test )\n",
    "\n",
    "# performance\n",
    "lr_result = ml_error( 'Linear Regression', np.expm1( y_test ), np.expm1( yhat_lr ) )\n",
    "lr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Linear Regression Model - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:31:17.921743Z",
     "start_time": "2020-01-08T11:31:13.983795Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr_result_cv = cross_validation( x_training, 5, 'Linear Regression', lr, verbose=False )\n",
    "lr_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Linear Regression Regularized Model - Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:31:18.728712Z",
     "start_time": "2020-01-08T11:31:17.927577Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "lrr = Lasso( alpha=0.01 ).fit( x_train, y_train )\n",
    "\n",
    "# prediction\n",
    "yhat_lrr = lrr.predict( x_test )\n",
    "\n",
    "# performance\n",
    "lrr_result = ml_error( 'Linear Regression - Lasso', np.expm1( y_test ), np.expm1( yhat_lrr ) )\n",
    "lrr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Lasso - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:31:22.248030Z",
     "start_time": "2020-01-08T11:31:18.735432Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lrr_result_cv = cross_validation( x_training, 5, 'Lasso', lrr, verbose=False )\n",
    "lrr_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T11:37:39.995818Z",
     "start_time": "2020-01-08T11:31:22.253568Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "rf = RandomForestRegressor( n_estimators=100, n_jobs=-1, random_state=42 ).fit( x_train, y_train )\n",
    "\n",
    "# prediction\n",
    "yhat_rf = rf.predict( x_test )\n",
    "\n",
    "# performance\n",
    "rf_result = ml_error( 'Random Forest Regressor', np.expm1( y_test ), np.expm1( yhat_rf ) )\n",
    "rf_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Random Forest Regressor - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T22:53:19.476256Z",
     "start_time": "2020-01-08T11:37:40.014756Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rf_result_cv = cross_validation( x_training, 5, 'Random Forest Regressor', rf, verbose=False )\n",
    "rf_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T23:04:18.335709Z",
     "start_time": "2020-01-08T22:53:19.494411Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model_xgb = xgb.XGBRegressor( objective='reg:squarederror',\n",
    "                              n_estimators=100, \n",
    "                              eta=0.03, \n",
    "                              max_depth=10, \n",
    "                              subsample=0.7,\n",
    "                              colsample_bytree=0.7 ).fit( x_train, y_train )\n",
    "\n",
    "# prediction\n",
    "yhat_xgb = model_xgb.predict( x_test )\n",
    "\n",
    "# performance\n",
    "xgb_result = ml_error( 'XGBoost Regressor', np.expm1( y_test ), np.expm1( yhat_xgb ) )\n",
    "xgb_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### XGBoost Regressor - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T23:45:33.183643Z",
     "start_time": "2020-01-08T23:04:18.349333Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xgb_result_cv = cross_validation( x_training, 5, 'XGBoost Regressor', model_xgb, verbose=True )\n",
    "xgb_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Compare Model's Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Single Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T23:45:33.260141Z",
     "start_time": "2020-01-08T23:45:33.190135Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "modelling_result = pd.concat( [baseline_result, lr_result, lrr_result, rf_result, xgb_result] )\n",
    "modelling_result.sort_values( 'RMSE' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Real Performance - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T23:45:33.284202Z",
     "start_time": "2020-01-08T23:45:33.266489Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "modelling_result_cv = pd.concat( [lr_result_cv, lrr_result_cv, rf_result_cv, xgb_result_cv] )\n",
    "modelling_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# HYPERPARAMETER FINE TUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T23:45:33.295487Z",
     "start_time": "2020-01-08T23:45:33.289860Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#param = {\n",
    "#    'n_estimators': [1500, 1700, 2500, 3000, 3500],\n",
    "#    'eta': [0.01, 0.03],\n",
    "#    'max_depth': [3, 5, 9],\n",
    "#    'subsample': [0.1, 0.5, 0.7],\n",
    "#    'colsample_bytree': [0.3, 0.7, 0.9],\n",
    "#    'min_child_weight': [3, 8, 15]\n",
    "#        }\n",
    "#\n",
    "#MAX_EVAL = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T23:45:33.311093Z",
     "start_time": "2020-01-08T23:45:33.301202Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#final_result = pd.DataFrame()\n",
    "#\n",
    "#for i in range( MAX_EVAL ):\n",
    "#    # choose values for parameters randomly\n",
    "#    hp = { k: random.sample( v, 1 )[0] for k, v in param.items() }\n",
    "#    print( hp )\n",
    "#    \n",
    "#    # model\n",
    "#    model_xgb = xgb.XGBRegressor( objective='reg:squarederror',\n",
    "#                                  n_estimators=hp['n_estimators'], \n",
    "#                                  eta=hp['eta'], \n",
    "#                                  max_depth=hp['max_depth'], \n",
    "#                                  subsample=hp['subsample'],\n",
    "#                                  colsample_bytee=hp['colsample_bytree'],\n",
    "#                                  min_child_weight=hp['min_child_weight'] )\n",
    "#\n",
    "#    # performance\n",
    "#    result = cross_validation( x_training, 5, 'XGBoost Regressor', model_xgb, verbose=True )\n",
    "#    final_result = pd.concat( [final_result, result] )\n",
    "#        \n",
    "#final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T23:45:33.341371Z",
     "start_time": "2020-01-08T23:45:33.315796Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T23:45:33.348773Z",
     "start_time": "2020-01-08T23:45:33.344536Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "param_tuned = {\n",
    "    'n_estimators': 3000,\n",
    "    'eta': 0.03,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'min_child_weight': 3 \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T01:16:23.481635Z",
     "start_time": "2020-01-08T23:45:33.355270Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model_xgb_tuned = xgb.XGBRegressor( objective='reg:squarederror',\n",
    "                                    n_estimators=param_tuned['n_estimators'], \n",
    "                                    eta=param_tuned['eta'], \n",
    "                                    max_depth=param_tuned['max_depth'], \n",
    "                                    subsample=param_tuned['subsample'],\n",
    "                                    colsample_bytree=param_tuned['colsample_bytree'],\n",
    "                                    min_child_weight=param_tuned['min_child_weight'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T01:16:23.481635Z",
     "start_time": "2020-01-08T23:45:33.355270Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_xgb_tuned.fit( x_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T01:16:23.481635Z",
     "start_time": "2020-01-08T23:45:33.355270Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# prediction\n",
    "yhat_xgb_tuned = model_xgb_tuned.predict( x_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T01:16:23.481635Z",
     "start_time": "2020-01-08T23:45:33.355270Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# performance\n",
    "xgb_result_tuned = ml_error( 'XGBoost Regressor', np.expm1( y_test ), np.expm1( yhat_xgb_tuned ) )\n",
    "xgb_result_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T01:16:23.508224Z",
     "start_time": "2020-01-09T01:16:23.486826Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mpe = mean_percentage_error( np.expm1( y_test ), np.expm1( yhat_xgb_tuned ) )\n",
    "mpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model( model_xgb_tuned, 'model_xgb_tuned.pkl' )\n",
    "save_model( xgb_result_tuned, 'xgb_result_tuned.pkl' )\n",
    "save_model( yhat_xgb_tuned, 'yhat_xgb_tuned.pkl' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# TRADUCAO E INTERPRETACAO DO ERRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:06:17.281841Z",
     "iopub.status.busy": "2021-10-29T21:06:17.281523Z",
     "iopub.status.idle": "2021-10-29T21:06:17.650275Z",
     "shell.execute_reply": "2021-10-29T21:06:17.649683Z",
     "shell.execute_reply.started": "2021-10-29T21:06:17.281805Z"
    }
   },
   "outputs": [],
   "source": [
    "model_xgb_tuned = load_model( 'model_xgb_tuned.pkl' )\n",
    "xgb_result_tuned = load_model( 'xgb_result_tuned.pkl' )\n",
    "yhat_xgb_tuned = load_model( 'yhat_xgb_tuned.pkl' )\n",
    "cols_selected_boruta_full = load_model( 'cols_selected_boruta_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:06:18.283894Z",
     "iopub.status.busy": "2021-10-29T21:06:18.283660Z",
     "iopub.status.idle": "2021-10-29T21:06:18.360154Z",
     "shell.execute_reply": "2021-10-29T21:06:18.359450Z",
     "shell.execute_reply.started": "2021-10-29T21:06:18.283868Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = load_model( 'X_train.pkl' )\n",
    "y_train = load_model( 'y_train.pkl' )\n",
    "X_test = load_model( 'X_test.pkl' )\n",
    "y_test = load_model( 'y_test.pkl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T10:03:19.356840Z",
     "start_time": "2020-01-11T10:03:19.330279Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-29T21:06:19.253495Z",
     "iopub.status.busy": "2021-10-29T21:06:19.253194Z",
     "iopub.status.idle": "2021-10-29T21:06:19.355983Z",
     "shell.execute_reply": "2021-10-29T21:06:19.354865Z",
     "shell.execute_reply.started": "2021-10-29T21:06:19.253465Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df9 = X_test[ cols_selected_boruta_full ]\n",
    "\n",
    "# rescale\n",
    "df9['sales'] = np.expm1( df9['sales'] )\n",
    "df9['predictions'] = np.expm1( yhat_xgb_tuned )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Business Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T10:11:51.084417Z",
     "start_time": "2020-01-11T10:11:48.452563Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-29T21:06:30.195468Z",
     "iopub.status.busy": "2021-10-29T21:06:30.195113Z",
     "iopub.status.idle": "2021-10-29T21:06:31.178527Z",
     "shell.execute_reply": "2021-10-29T21:06:31.177954Z",
     "shell.execute_reply.started": "2021-10-29T21:06:30.195436Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sum of predictions\n",
    "df91 = df9[['store', 'predictions']].groupby( 'store' ).sum().reset_index()\n",
    "\n",
    "# MAE and MAPE\n",
    "df9_aux1 = df9[['store', 'sales', 'predictions']].groupby( 'store' ).apply( lambda x: mean_absolute_error( x['sales'], x['predictions'] ) ).reset_index().rename( columns={0:'MAE'})\n",
    "df9_aux2 = df9[['store', 'sales', 'predictions']].groupby( 'store' ).apply( lambda x: mean_absolute_percentage_error( x['sales'], x['predictions'] ) ).reset_index().rename( columns={0:'MAPE'})\n",
    "\n",
    "# Merge\n",
    "df9_aux3 = pd.merge( df9_aux1, df9_aux2, how='inner', on='store' )\n",
    "df92 = pd.merge( df91, df9_aux3, how='inner', on='store' )\n",
    "\n",
    "# Scenarios\n",
    "df92['worst_scenario'] = df92['predictions'] - df92['MAE']\n",
    "df92['best_scenario'] = df92['predictions'] + df92['MAE']\n",
    "\n",
    "# order columns\n",
    "df92 = df92[['store', 'predictions', 'worst_scenario', 'best_scenario', 'MAE', 'MAPE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T10:18:27.182216Z",
     "start_time": "2020-01-11T10:18:27.106247Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-29T21:06:34.645688Z",
     "iopub.status.busy": "2021-10-29T21:06:34.644854Z",
     "iopub.status.idle": "2021-10-29T21:06:34.727641Z",
     "shell.execute_reply": "2021-10-29T21:06:34.726851Z",
     "shell.execute_reply.started": "2021-10-29T21:06:34.645603Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>predictions</th>\n",
       "      <th>worst_scenario</th>\n",
       "      <th>best_scenario</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>292</td>\n",
       "      <td>108,359.7891</td>\n",
       "      <td>104,977.6086</td>\n",
       "      <td>111,741.9695</td>\n",
       "      <td>3,382.1804</td>\n",
       "      <td>60.2768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>909</td>\n",
       "      <td>220,300.0781</td>\n",
       "      <td>212,395.1411</td>\n",
       "      <td>228,205.0152</td>\n",
       "      <td>7,904.9371</td>\n",
       "      <td>51.8675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>876</td>\n",
       "      <td>194,060.8125</td>\n",
       "      <td>189,924.5347</td>\n",
       "      <td>198,197.0903</td>\n",
       "      <td>4,136.2778</td>\n",
       "      <td>33.7730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>170</td>\n",
       "      <td>201,541.6875</td>\n",
       "      <td>200,194.4216</td>\n",
       "      <td>202,888.9534</td>\n",
       "      <td>1,347.2659</td>\n",
       "      <td>33.2923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>749</td>\n",
       "      <td>206,800.9531</td>\n",
       "      <td>205,789.1920</td>\n",
       "      <td>207,812.7142</td>\n",
       "      <td>1,011.7611</td>\n",
       "      <td>28.3049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     store  predictions  worst_scenario  best_scenario        MAE    MAPE\n",
       "291    292 108,359.7891    104,977.6086   111,741.9695 3,382.1804 60.2768\n",
       "908    909 220,300.0781    212,395.1411   228,205.0152 7,904.9371 51.8675\n",
       "875    876 194,060.8125    189,924.5347   198,197.0903 4,136.2778 33.7730\n",
       "169    170 201,541.6875    200,194.4216   202,888.9534 1,347.2659 33.2923\n",
       "748    749 206,800.9531    205,789.1920   207,812.7142 1,011.7611 28.3049"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df92.sort_values( 'MAPE', ascending=False ).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T10:18:27.182216Z",
     "start_time": "2020-01-11T10:18:27.106247Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-29T21:06:50.769774Z",
     "iopub.status.busy": "2021-10-29T21:06:50.769565Z",
     "iopub.status.idle": "2021-10-29T21:06:50.779131Z",
     "shell.execute_reply": "2021-10-29T21:06:50.778576Z",
     "shell.execute_reply.started": "2021-10-29T21:06:50.769751Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>predictions</th>\n",
       "      <th>worst_scenario</th>\n",
       "      <th>best_scenario</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>1089</td>\n",
       "      <td>373,394.1875</td>\n",
       "      <td>372,825.1184</td>\n",
       "      <td>373,963.2566</td>\n",
       "      <td>569.0691</td>\n",
       "      <td>5.3232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>667</td>\n",
       "      <td>315,185.8438</td>\n",
       "      <td>314,693.4028</td>\n",
       "      <td>315,678.2847</td>\n",
       "      <td>492.4410</td>\n",
       "      <td>5.5487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>323</td>\n",
       "      <td>282,916.4688</td>\n",
       "      <td>282,488.0610</td>\n",
       "      <td>283,344.8765</td>\n",
       "      <td>428.4077</td>\n",
       "      <td>5.6277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>742</td>\n",
       "      <td>301,657.5312</td>\n",
       "      <td>301,199.1451</td>\n",
       "      <td>302,115.9174</td>\n",
       "      <td>458.3861</td>\n",
       "      <td>5.6393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>1097</td>\n",
       "      <td>450,342.1562</td>\n",
       "      <td>449,703.2118</td>\n",
       "      <td>450,981.1007</td>\n",
       "      <td>638.9445</td>\n",
       "      <td>5.7761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      store  predictions  worst_scenario  best_scenario      MAE   MAPE\n",
       "1088   1089 373,394.1875    372,825.1184   373,963.2566 569.0691 5.3232\n",
       "666     667 315,185.8438    314,693.4028   315,678.2847 492.4410 5.5487\n",
       "322     323 282,916.4688    282,488.0610   283,344.8765 428.4077 5.6277\n",
       "741     742 301,657.5312    301,199.1451   302,115.9174 458.3861 5.6393\n",
       "1096   1097 450,342.1562    449,703.2118   450,981.1007 638.9445 5.7761"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df92.sort_values( 'MAPE', ascending=True ).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T10:19:39.901937Z",
     "start_time": "2020-01-11T10:19:37.967116Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot( x='store', y='MAPE', data=df92 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Total Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T10:22:54.014958Z",
     "start_time": "2020-01-11T10:22:53.965585Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df93 = df92[['predictions', 'worst_scenario', 'best_scenario']].apply( lambda x: np.sum( x ), axis=0 ).reset_index().rename( columns={'index': 'Scenario', 0:'Values'} )\n",
    "df93['Values'] = df93['Values'].map( 'R${:,.2f}'.format )\n",
    "df93"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Machine Learning Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T10:24:20.379912Z",
     "start_time": "2020-01-11T10:24:20.372687Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df9['error'] = df9['sales'] - df9['predictions']\n",
    "df9['error_rate'] = df9['predictions'] / df9['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T10:29:16.377479Z",
     "start_time": "2020-01-11T10:29:02.514740Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.subplot( 2, 2, 1 )\n",
    "sns.lineplot( x='date', y='sales', data=df9, label='SALES' )\n",
    "sns.lineplot( x='date', y='predictions', data=df9, label='PREDICTIONS' )\n",
    "\n",
    "plt.subplot( 2, 2, 2 )\n",
    "sns.lineplot( x='date', y='error_rate', data=df9 )\n",
    "plt.axhline( 1, linestyle='--')\n",
    "\n",
    "plt.subplot( 2, 2, 3 )\n",
    "sns.distplot( df9['error'] )\n",
    "\n",
    "plt.subplot( 2, 2, 4 )\n",
    "sns.scatterplot( df9['predictions'], df9['error'] );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# DEPLOY MODEL TO PRODUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model( model_xgb_tuned, 'rossmann_model.pkl' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Rossmann Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-12T19:55:37.619812Z",
     "start_time": "2020-01-12T19:55:37.555888Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "import inflection\n",
    "\n",
    "class Rossmann_c06( object ):\n",
    "    def __init__( self ):\n",
    "        self.home_path='/home/rodrigo/Projetos/Comunidade_DS/data_science_producao/'\n",
    "        self.competition_distance_scaler   = pickle.load( open( self.home_path + 'models/competition_distance_scaler.pkl', 'rb') )\n",
    "        self.competition_time_month_scaler = pickle.load( open( self.home_path + 'models/competition_time_month_scaler.pkl', 'rb') )\n",
    "        self.promo_time_week_scaler        = pickle.load( open( self.home_path + 'models/promo_time_week_scaler.pkl', 'rb') )\n",
    "        self.year_scaler                   = pickle.load( open( self.home_path + 'models/year_scaler.pkl', 'rb') )\n",
    "        self.store_type_scaler             = pickle.load( open( self.home_path + 'models/store_type_scaler.pkl', 'rb') )\n",
    "        \n",
    "        \n",
    "    def data_cleaning( self, df1 ): \n",
    "        \n",
    "        ## 1.1. Rename Columns\n",
    "        cols_old = ['Store', 'DayOfWeek', 'Date', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', \n",
    "                    'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
    "                    'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
    "\n",
    "        snakecase = lambda x: inflection.underscore( x )\n",
    "\n",
    "        cols_new = list( map( snakecase, cols_old ) )\n",
    "\n",
    "        #rename\n",
    "        df1.columns = cols_new\n",
    "    \n",
    "        ## 1.3. Data Types\n",
    "        df1['date'] = pd.to_datetime( df1['date'] )\n",
    "\n",
    "        ## 1.5. Fillout NA\n",
    "        #competition_distance        \n",
    "        df1['competition_distance'] = df1['competition_distance'].apply( lambda x: 100000.0 if math.isnan( x ) else x )\n",
    "\n",
    "        #competition_open_since_month\n",
    "        df1['competition_open_since_month'] = df1.apply( lambda x: x['date'].month if math.isnan( x['competition_open_since_month'] ) else x['competition_open_since_month'], axis=1 )\n",
    "\n",
    "        #competition_open_since_year \n",
    "        df1['competition_open_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan( x['competition_open_since_year'] ) else x['competition_open_since_year'], axis=1 )\n",
    "\n",
    "        #promo2_since_week           \n",
    "        df1['promo2_since_week'] = df1.apply( lambda x: x['date'].week if math.isnan( x['promo2_since_week'] ) else x['promo2_since_week'], axis=1 )\n",
    "\n",
    "        #promo2_since_year           \n",
    "        df1['promo2_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan( x['promo2_since_year'] ) else x['promo2_since_year'], axis=1 )\n",
    "\n",
    "        #promo_interval              \n",
    "        month_map = {1: 'Jan',  2: 'Fev',  3: 'Mar',  4: 'Apr',  5: 'May',  6: 'Jun',  7: 'Jul',  8: 'Aug',  9: 'Sep',  10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
    "\n",
    "        df1['promo_interval'].fillna(0, inplace=True )\n",
    "\n",
    "        df1['month_map'] = df1['date'].dt.month.map( month_map )\n",
    "\n",
    "        df1['is_promo'] = df1[['promo_interval', 'month_map']].apply( lambda x: 0 if x['promo_interval'] == 0 else 1 if x['month_map'] in x['promo_interval'].split( ',' ) else 0, axis=1 )\n",
    "\n",
    "        ## 1.6. Change Data Types\n",
    "        # competiton\n",
    "        df1['competition_open_since_month'] = df1['competition_open_since_month'].astype( int )\n",
    "        df1['competition_open_since_year'] = df1['competition_open_since_year'].astype( int )\n",
    "\n",
    "        # promo2\n",
    "        df1['promo2_since_week'] = df1['promo2_since_week'].astype( int )\n",
    "        df1['promo2_since_year'] = df1['promo2_since_year'].astype( int )\n",
    "        \n",
    "        return df1 \n",
    "\n",
    "\n",
    "    def feature_engineering( self, df2 ):\n",
    "\n",
    "        # year\n",
    "        df2['year'] = df2['date'].dt.year\n",
    "\n",
    "        # month\n",
    "        df2['month'] = df2['date'].dt.month\n",
    "\n",
    "        # day\n",
    "        df2['day'] = df2['date'].dt.day\n",
    "\n",
    "        # week of year\n",
    "        df2['week_of_year'] = df2['date'].dt.weekofyear\n",
    "\n",
    "        # year week\n",
    "        df2['year_week'] = df2['date'].dt.strftime( '%Y-%W' )\n",
    "\n",
    "        # competition since\n",
    "        df2['competition_since'] = df2.apply( lambda x: datetime.datetime( year=x['competition_open_since_year'], month=x['competition_open_since_month'],day=1 ), axis=1 )\n",
    "        df2['competition_time_month'] = ( ( df2['date'] - df2['competition_since'] )/30 ).apply( lambda x: x.days ).astype( int )\n",
    "\n",
    "        # promo since\n",
    "        df2['promo_since'] = df2['promo2_since_year'].astype( str ) + '-' + df2['promo2_since_week'].astype( str )\n",
    "        df2['promo_since'] = df2['promo_since'].apply( lambda x: datetime.datetime.strptime( x + '-1', '%Y-%W-%w' ) - datetime.timedelta( days=7 ) )\n",
    "        df2['promo_time_week'] = ( ( df2['date'] - df2['promo_since'] )/7 ).apply( lambda x: x.days ).astype( int )\n",
    "\n",
    "        # assortment\n",
    "        df2['assortment'] = df2['assortment'].apply( lambda x: 'basic' if x == 'a' else 'extra' if x == 'b' else 'extended' )\n",
    "\n",
    "        # state holiday\n",
    "        df2['state_holiday'] = df2['state_holiday'].apply( lambda x: 'public_holiday' if x == 'a' else 'easter_holiday' if x == 'b' else 'christmas' if x == 'c' else 'regular_day' )\n",
    "\n",
    "        # 3.0. PASSO 03 - FILTRAGEM DE VARIÁVEIS\n",
    "        ## 3.1. Filtragem das Linhas\n",
    "        df2 = df2[df2['open'] != 0]\n",
    "\n",
    "        ## 3.2. Selecao das Colunas\n",
    "        cols_drop = ['open', 'promo_interval', 'month_map']\n",
    "        df2 = df2.drop( cols_drop, axis=1 )\n",
    "        \n",
    "        return df2\n",
    "\n",
    "\n",
    "    def data_preparation( self, df5 ):\n",
    "\n",
    "        ## 5.2. Rescaling \n",
    "        # competition distance\n",
    "        df5['competition_distance'] = self.competition_distance_scaler.fit_transform( df5[['competition_distance']].values )\n",
    "    \n",
    "        # competition time month\n",
    "        df5['competition_time_month'] = self.competition_time_month_scaler.fit_transform( df5[['competition_time_month']].values )\n",
    "\n",
    "        # promo time week\n",
    "        df5['promo_time_week'] = self.promo_time_week_scaler.fit_transform( df5[['promo_time_week']].values )\n",
    "        \n",
    "        # year\n",
    "        df5['year'] = self.year_scaler.fit_transform( df5[['year']].values )\n",
    "\n",
    "        ### 5.3.1. Encoding\n",
    "        # state_holiday - One Hot Encoding\n",
    "        df5 = pd.get_dummies( df5, prefix=['state_holiday'], columns=['state_holiday'] )\n",
    "\n",
    "        # store_type - Label Encoding\n",
    "        df5['store_type'] = self.store_type_scaler.fit_transform( df5['store_type'] )\n",
    "\n",
    "        # assortment - Ordinal Encoding\n",
    "        assortment_dict = {'basic': 1,  'extra': 2, 'extended': 3}\n",
    "        df5['assortment'] = df5['assortment'].map( assortment_dict )\n",
    "\n",
    "        \n",
    "        ### 5.3.3. Nature Transformation\n",
    "        # day of week\n",
    "        df5['day_of_week_sin'] = df5['day_of_week'].apply( lambda x: np.sin( x * ( 2. * np.pi/7 ) ) )\n",
    "        df5['day_of_week_cos'] = df5['day_of_week'].apply( lambda x: np.cos( x * ( 2. * np.pi/7 ) ) )\n",
    "\n",
    "        # month\n",
    "        df5['month_sin'] = df5['month'].apply( lambda x: np.sin( x * ( 2. * np.pi/12 ) ) )\n",
    "        df5['month_cos'] = df5['month'].apply( lambda x: np.cos( x * ( 2. * np.pi/12 ) ) )\n",
    "\n",
    "        # day \n",
    "        df5['day_sin'] = df5['day'].apply( lambda x: np.sin( x * ( 2. * np.pi/30 ) ) )\n",
    "        df5['day_cos'] = df5['day'].apply( lambda x: np.cos( x * ( 2. * np.pi/30 ) ) )\n",
    "\n",
    "        # week of year\n",
    "        df5['week_of_year_sin'] = df5['week_of_year'].apply( lambda x: np.sin( x * ( 2. * np.pi/52 ) ) )\n",
    "        df5['week_of_year_cos'] = df5['week_of_year'].apply( lambda x: np.cos( x * ( 2. * np.pi/52 ) ) )\n",
    "        \n",
    "        \n",
    "        cols_selected = [ 'store', 'promo', 'store_type', 'assortment', 'competition_distance', 'competition_open_since_month',\n",
    "            'competition_open_since_year', 'promo2', 'promo2_since_week', 'promo2_since_year', 'competition_time_month', 'promo_time_week',\n",
    "            'day_of_week_sin', 'day_of_week_cos', 'month_sin', 'month_cos', 'day_sin', 'day_cos', 'week_of_year_sin', 'week_of_year_cos']\n",
    "        \n",
    "        return df5[ cols_selected ]\n",
    "    \n",
    "    \n",
    "    def get_prediction( self, model, original_data, test_data ):\n",
    "        # prediction\n",
    "        pred = model.predict( test_data )\n",
    "        \n",
    "        # join pred into the original data\n",
    "        original_data['prediction'] = np.expm1( pred )\n",
    "        \n",
    "        return original_data.to_json( orient='records', date_format='iso' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## API Handler - to Heroku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-12T19:56:10.881620Z",
     "start_time": "2020-01-12T19:56:10.490135Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from flask import Flask, request, Response, send_from_directory\n",
    "from rossmann.rossmann import Rossmann_c06\n",
    "\n",
    "# loading model\n",
    "model = pickle.load( open( 'models/rossmann_model.pkl', 'rb') )\n",
    "\n",
    "# initialize API\n",
    "app = Flask( __name__ )\n",
    "\n",
    "@app.get(\"/hello\" )\n",
    "def healthcheck():\n",
    "    return Response( '{}', status=200, mimetype='application/json' )\n",
    "\n",
    "\n",
    "@app.route('/favicon.ico')\n",
    "def favicon():\n",
    "    return send_from_directory(os.path.join(app.root_path, 'static'), 'favicon.ico', mimetype='image/vnd.microsoft.icon')\n",
    "\n",
    "\n",
    "@app.route( '/rossmann/predict', methods=['POST'] )\n",
    "def rossmann_predict():\n",
    "    test_json = request.get_json()\n",
    "   \n",
    "    if test_json: # there is data\n",
    "        if isinstance( test_json, dict ): # unique example\n",
    "            test_raw = pd.DataFrame( test_json, index=[0] )\n",
    "            \n",
    "        else: # multiple example\n",
    "            test_raw = pd.DataFrame( test_json, columns=test_json[0].keys() )\n",
    "            \n",
    "        # Instantiate Rossmann class\n",
    "        pipeline = Rossmann_c06()\n",
    "        \n",
    "        # data cleaning\n",
    "        df1 = pipeline.data_cleaning( test_raw )\n",
    "        \n",
    "        # feature engineering\n",
    "        df2 = pipeline.feature_engineering( df1 )\n",
    "        \n",
    "        # data preparation\n",
    "        df3 = pipeline.data_preparation( df2 )\n",
    "        \n",
    "        # prediction\n",
    "        df_response = pipeline.get_prediction( model, test_raw, df3 )\n",
    "        \n",
    "        return df_response\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        return Response( '{}', status=200, mimetype='application/json' )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    port = os.environ.get( 'PORT', 5000 )\n",
    "    app.run( host='0.0.0.0', port = port )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-12T20:31:54.144442Z",
     "start_time": "2020-01-12T20:31:54.030073Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-27T22:11:30.666529Z",
     "iopub.status.busy": "2021-10-27T22:11:30.666189Z",
     "iopub.status.idle": "2021-10-27T22:11:30.670352Z",
     "shell.execute_reply": "2021-10-27T22:11:30.669883Z",
     "shell.execute_reply.started": "2021-10-27T22:11:30.666488Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# loading test dataset\n",
    "import json\n",
    "import requests\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-12T20:31:54.144442Z",
     "start_time": "2020-01-12T20:31:54.030073Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-27T23:17:22.014414Z",
     "iopub.status.busy": "2021-10-27T23:17:22.014211Z",
     "iopub.status.idle": "2021-10-27T23:17:22.040587Z",
     "shell.execute_reply": "2021-10-27T23:17:22.040009Z",
     "shell.execute_reply.started": "2021-10-27T23:17:22.014391Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df10 = pd.read_csv( '/home/rodrigo/Projetos/Comunidade_DS/data_science_producao/data/raw/test.csv', low_memory=False)\n",
    "df_store_raw = pd.read_csv('/home/rodrigo/Projetos/Comunidade_DS/data_science_producao/data/raw/store.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-12T20:32:49.000535Z",
     "start_time": "2020-01-12T20:32:48.869756Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-27T23:17:22.869508Z",
     "iopub.status.busy": "2021-10-27T23:17:22.869214Z",
     "iopub.status.idle": "2021-10-27T23:17:22.886641Z",
     "shell.execute_reply": "2021-10-27T23:17:22.886140Z",
     "shell.execute_reply.started": "2021-10-27T23:17:22.869479Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# merge test dataset + store\n",
    "df_test = pd.merge( df10, df_store_raw, how='left', on='Store' )\n",
    "\n",
    "pickle.dump( df_test, open('../webapp/df_test.pkl', 'wb'))\n",
    "\n",
    "df_test = pickle.load( open('../webapp/df_test.pkl', 'rb') )\n",
    "\n",
    "# choose store for prediction\n",
    "df_test = df_test[df_test['Store'].isin( [20, 12, 22, 50, 74] )]\n",
    "\n",
    "# remove closed days\n",
    "df_test = df_test[df_test['Open'] != 0]\n",
    "df_test = df_test[~df_test['Open'].isnull()]\n",
    "df_test = df_test.drop( 'Id', axis=1 )\n",
    "\n",
    "# convert Dataframe to json\n",
    "data = json.dumps( df_test.to_dict( orient='records' ) )\n",
    "\n",
    "# API Call\n",
    "# url = 'http://0.0.0.0:5000/rossmann/predict'\n",
    "url = 'https://rossmann-api.herokuapp.com/rossmann/predict'\n",
    "header = {'Content-type': 'application/json' } \n",
    "\n",
    "r = requests.post( url, data=data, headers=header )\n",
    "print( 'Status Code {}'.format( r.status_code ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-12T20:32:51.406254Z",
     "start_time": "2020-01-12T20:32:51.380244Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-27T23:21:58.083612Z",
     "iopub.status.busy": "2021-10-27T23:21:58.083332Z",
     "iopub.status.idle": "2021-10-27T23:21:58.321991Z",
     "shell.execute_reply": "2021-10-27T23:21:58.321443Z",
     "shell.execute_reply.started": "2021-10-27T23:21:58.083583Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d1 = pd.DataFrame( r.json(), columns=r.json()[0].keys() )\n",
    "\n",
    "d2 = d1[['store', 'prediction']].groupby( 'store' ).sum().reset_index()\n",
    "\n",
    "for i in range( len( d2 ) ):\n",
    "    print( 'Store Number {} will sell R$ {:,.2f} in the next 6 weeks'.format( \n",
    "            d2.loc[i, 'store'], \n",
    "            d2.loc[i, 'prediction'] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rossmann Telegram BOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from flask import Flask, request, Response, send_from_directory\n",
    "\n",
    "# constants\n",
    "TOKEN = ''\n",
    "\n",
    "def send_message( chat_id, text ):\n",
    "    global TOKEN\n",
    "    url = 'https://api.telegram.org/bot{}/'.format( TOKEN ) \n",
    "    url = url + 'sendMessage?chat_id={}'.format( chat_id ) \n",
    "\n",
    "    r = requests.post( url, json={'text': text } )\n",
    "    print( 'Status Code {}'.format( r.status_code ) )\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_dataset( store_id ) -> object:\n",
    "    # loading test dataset\n",
    "    df10 = pd.read_csv( 'test.csv' )\n",
    "    df_store_raw = pd.read_csv( 'store.csv' )\n",
    "\n",
    "    # merge test dataset + store\n",
    "    df_test = pd.merge( df10, df_store_raw, how='left', on='Store' )\n",
    "\n",
    "    # choose store for prediction\n",
    "    df_test = df_test[df_test['Store'] == store_id]\n",
    "\n",
    "    if df_test.empty:\n",
    "        data = 'error'\n",
    "\n",
    "    else:\n",
    "        # remove closed days\n",
    "        df_test = df_test[df_test['Open'] != 0]\n",
    "        df_test = df_test[~df_test['Open'].isnull()]\n",
    "        df_test = df_test.drop( 'Id', axis=1 )\n",
    "\n",
    "        # convert Dataframe to json\n",
    "        data = json.dumps( df_test.to_dict( orient='records' ) )\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def predict( data ):\n",
    "    # API Call\n",
    "    url = 'https://rossmann-api.herokuapp.com/rossmann/predict'\n",
    "    header = {'Content-type': 'application/json' }\n",
    "\n",
    "    r = requests.post( url, data=data, headers=header )\n",
    "    print( 'Status Code {}'.format( r.status_code ) )\n",
    "\n",
    "    d1 = pd.DataFrame( r.json(), columns=r.json()[0].keys() )\n",
    "\n",
    "    return d1\n",
    "\n",
    "\n",
    "def parse_message( message ):\n",
    "    chat_id = message['message']['chat']['id']\n",
    "    store_id = message['message']['text']\n",
    "\n",
    "    store_id = store_id.replace( '/', '' )\n",
    "\n",
    "    try:\n",
    "        store_id = int( store_id )\n",
    "\n",
    "    except ValueError:\n",
    "        store_id = 'error'\n",
    "\n",
    "    return chat_id, store_id\n",
    "\n",
    "\n",
    "# API initialize\n",
    "app = Flask( __name__ )\n",
    "\n",
    "@app.route('/favicon.ico')\n",
    "def favicon():\n",
    "    return send_from_directory(os.path.join(app.root_path, 'static'),\n",
    "                               'favicon.ico', mimetype='image/vnd.microsoft.icon')\n",
    "\n",
    "\n",
    "@app.route( '/', methods=['GET', 'POST'] )\n",
    "def index():\n",
    "    if request.method == 'POST':\n",
    "        message = request.get_json()\n",
    "\n",
    "        chat_id, store_id = parse_message( message )\n",
    "\n",
    "        if store_id == 'error':\n",
    "            send_message( chat_id, 'Store ID is Wrong' )\n",
    "            return Response( 'Ok', status=200 )\n",
    "\n",
    "        else:\n",
    "            data = load_dataset( store_id ) # loading data\n",
    "\n",
    "            if data == 'error' :\n",
    "                send_message( chat_id, 'Store Not Available' )\n",
    "                return Response( 'Ok', status=200 )\n",
    "\n",
    "            else:\n",
    "                d1 = predict( data ) # prediction\n",
    "                d2 = d1[['store', 'prediction']].groupby( 'store' ).sum().reset_index() # compute\n",
    "                msg = 'Store Number {} will sell R$ {:,.2f} in the next 6 weeks'.format( d2['store'].values[0], d2['prediction'].values[0] )\n",
    "                send_message( chat_id, msg )  # return data\n",
    "                return Response( 'Ok', status=200 )\n",
    "\n",
    "    else:\n",
    "        return '<h1> Rossmann Telegram BOT </h1>'\n",
    "\n",
    "if __name__ == '__main__' :\n",
    "    port = os.environ.get( 'PORT', 5000 )\n",
    "    app.run( host='0.0.0.0', port=port )"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {
    "height": "11.6667px",
    "width": "178px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Etapas de Projeto",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "276.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
